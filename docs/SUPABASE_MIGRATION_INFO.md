# üìã Informacje o Aplikacji i Bazie Danych - Migracja Supabase

## üéØ Co Robi Ta Aplikacja?

**Nazwa:** TGM Research - Coding & AI Categorization Dashboard

**Typ:** Enterprise SaaS do kategoryzacji danych badawczych

**Opis:** Profesjonalna aplikacja webowa do kategoryzacji odpowiedzi z bada≈Ñ/ankiet przy u≈ºyciu AI (GPT-4) i manualnego kodowania.

### G≈Ç√≥wne Funkcje:
- üìä **ZarzƒÖdzanie kategoriami** - Tworzenie i organizacja kategorii kodowania
- üè∑Ô∏è **ZarzƒÖdzanie kodami** - Definiowanie kod√≥w i przypisywanie do wielu kategorii
- ü§ñ **AI-Powered Suggestions** - Automatyczne sugestie kod√≥w przez GPT-4
- ‚úÖ **Manualna kategoryzacja** - PrzeglƒÖdanie i potwierdzanie sugestii AI
- üîç **Zaawansowane filtrowanie** - Wyszukiwanie i filtrowanie po wielu kryteriach
- üìà **Dashboard statystyk** - ≈öledzenie postƒôp√≥w kategoryzacji
- ‚ö° **Auto-Confirm Agent** - Automatyczne potwierdzanie sugestii AI o wysokiej pewno≈õci (‚â•90%)
- üì¶ **Operacje masowe** - Whitelist/Blacklist wielu odpowiedzi naraz
- üîÑ **Real-time Sync** - Aktualizacje na ≈ºywo przez Supabase realtime
- üé≠ **Virtual Scrolling** - Obs≈Çuga 10,000+ odpowiedzi bez problem√≥w z wydajno≈õciƒÖ

### Skala Projektu:
- **Obs≈Çuguje:** 10,000+ wierszy danych
- **Testy:** 113 test√≥w (69 unit + 44 E2E)
- **Komponenty:** 50+
- **Linie kodu:** ~15,000
- **Coverage:** 95%+ (critical code)

---

## üóÑÔ∏è Czy Ma W≈ÇasnƒÖ Bazƒô Danych w Supabase?

**TAK** - Aplikacja korzysta z **w≈Çasnej bazy danych PostgreSQL w Supabase**.

### Konfiguracja:
- **Backend:** Supabase (PostgreSQL + Auth + Realtime)
- **Frontend:** React 19 + TypeScript + Vite
- **API Server:** Node.js + Express (opcjonalnie, dla integracji GPT)
- **AI Engine:** OpenAI GPT-4

### Zmienne ≈örodowiskowe:
```env
VITE_SUPABASE_URL=your_supabase_project_url
VITE_SUPABASE_ANON_KEY=your_supabase_anon_key
VITE_API_URL=http://localhost:3001  # opcjonalnie
OPENAI_API_KEY=your_openai_api_key  # opcjonalnie
```

---

## üìä G≈Ç√≥wne Tabele w Bazie Danych

### 1. **`answers`** (Tabela G≈Ç√≥wna - Odpowiedzi z Bada≈Ñ)

**Opis:** Przechowuje wszystkie odpowiedzi z ankiet/bada≈Ñ do kategoryzacji.

**Kolumny:**
```sql
id                  BIGSERIAL PRIMARY KEY
answer_text         TEXT NOT NULL              -- Oryginalny tekst odpowiedzi
translation         TEXT                       -- T≈Çumaczenie (edytowalne przez u≈ºytkownika)
translation_en      TEXT                       -- T≈Çumaczenie EN (generowane przez AI)
language            TEXT                       -- Jƒôzyk odpowiedzi (np. "PL", "EN")
country             TEXT                       -- Kraj (np. "Poland", "USA")
quick_status        TEXT                       -- 'Other', 'Ignore', 'Global Blacklist', 'Blacklist', 'Confirmed'
general_status      TEXT                       -- Status og√≥lny (alias do 'status')
selected_code       TEXT                       -- Wybrany kod przez u≈ºytkownika
ai_suggested_code   TEXT                       -- Kod zaproponowany przez AI (top suggestion)
ai_suggestions      JSONB                      -- Pe≈Çne sugestie AI z confidence scores
category_id         BIGINT REFERENCES categories(id)
coding_date         TIMESTAMPTZ                -- Data kodowania
confirmed_by        TEXT                       -- Email u≈ºytkownika, kt√≥ry potwierdzi≈Ç
created_at          TIMESTAMPTZ DEFAULT NOW()
updated_at          TIMESTAMPTZ DEFAULT NOW()
```

**Indeksy:**
```sql
idx_answers_language        ON language
idx_answers_country         ON country
idx_answers_general_status  ON general_status
idx_answers_quick_status    ON quick_status
idx_answers_coding_date     ON coding_date DESC
idx_answers_ai_suggestions  USING GIN (ai_suggestions)  -- JSONB index
```

**Szacowana liczba wierszy:** 10,000+ (zale≈ºnie od u≈ºycia)

**Przyk≈Çad JSONB w `ai_suggestions`:**
```json
{
  "suggestions": [
    {
      "code_id": "123",
      "code_name": "Nike",
      "confidence": 0.95,
      "reasoning": "User mentioned nike in response"
    },
    {
      "code_id": "456",
      "code_name": "Adidas",
      "confidence": 0.75,
      "reasoning": "Similar brand mentioned secondarily"
    }
  ],
  "model": "gpt-4.1-nano",
  "timestamp": "2025-10-07T12:00:00Z",
  "preset_used": "LLM Brand List"
}
```

---

### 2. **`categories`** (Kategorie Kodowania)

**Opis:** Kategorie do organizacji kod√≥w (np. "Home Fragrances", "Sports Brands").

**Kolumny:**
```sql
id               BIGSERIAL PRIMARY KEY
name             TEXT NOT NULL UNIQUE
slug             TEXT GENERATED ALWAYS AS (regexp_replace(lower(name), '[^a-z0-9]+', '-', 'g')) STORED
use_web_context  BOOLEAN DEFAULT TRUE    -- Czy u≈ºywaƒá Google Search context dla AI
created_at       TIMESTAMPTZ DEFAULT NOW()
updated_at       TIMESTAMPTZ DEFAULT NOW()
```

**Indeksy:**
```sql
UNIQUE INDEX on name
INDEX on slug
```

**Szacowana liczba wierszy:** 10-50 kategorii

---

### 3. **`codes`** (Kody Kategoryzacji)

**Opis:** Kody do przypisywania odpowiedziom (np. "Nike", "Adidas", "Lavender").

**Kolumny:**
```sql
id              BIGSERIAL PRIMARY KEY
name            TEXT NOT NULL UNIQUE
slug            TEXT GENERATED ALWAYS AS (regexp_replace(lower(name), '[^a-z0-9]+', '-', 'g')) STORED
is_whitelisted  BOOLEAN DEFAULT FALSE   -- Automatyczne przypisywanie przy dopasowaniu
created_at      TIMESTAMPTZ DEFAULT NOW()
updated_at      TIMESTAMPTZ DEFAULT NOW()
```

**Indeksy:**
```sql
idx_codes_slug             ON slug
idx_codes_is_whitelisted   ON is_whitelisted
UNIQUE INDEX on name
```

**Szacowana liczba wierszy:** 50-500 kod√≥w

---

### 4. **`codes_categories`** (Relacja N:M - Kody ‚Üî Kategorie)

**Opis:** Tabela ≈ÇƒÖczƒÖca kody z kategoriami (jeden kod mo≈ºe nale≈ºeƒá do wielu kategorii).

**Kolumny:**
```sql
code_id      BIGINT NOT NULL REFERENCES codes(id) ON DELETE CASCADE
category_id  BIGINT NOT NULL REFERENCES categories(id) ON DELETE CASCADE
PRIMARY KEY (code_id, category_id)
```

**Indeksy:**
```sql
PRIMARY KEY on (code_id, category_id)
```

**Szacowana liczba wierszy:** 100-1000 relacji

---

### 5. **`answer_codes`** (Relacja N:M - Odpowiedzi ‚Üî Kody)

**Opis:** Tabela ≈ÇƒÖczƒÖca odpowiedzi z kodami (jedna odpowied≈∫ mo≈ºe mieƒá wiele kod√≥w).

**Kolumny:**
```sql
answer_id  BIGINT REFERENCES answers(id) ON DELETE CASCADE
code_id    BIGINT REFERENCES codes(id) ON DELETE CASCADE
PRIMARY KEY (answer_id, code_id)
```

**Szacowana liczba wierszy:** 10,000+ relacji (zale≈ºnie od liczby odpowiedzi)

---

### 6. **`file_imports`** (Historia Import√≥w Plik√≥w)

**Opis:** ≈öledzenie wszystkich import√≥w plik√≥w CSV/Excel do audytu.

**Kolumny:**
```sql
id                    UUID PRIMARY KEY DEFAULT gen_random_uuid()
file_name             TEXT NOT NULL
category_name         TEXT
category_id           BIGINT REFERENCES categories(id) ON DELETE SET NULL
rows_imported         INTEGER DEFAULT 0
rows_skipped          INTEGER DEFAULT 0
user_email            TEXT DEFAULT 'system'
status                TEXT CHECK (status IN ('success', 'failed', 'partial'))
error_message         TEXT
file_size_kb          NUMERIC(10, 2)
processing_time_ms    INTEGER
created_at            TIMESTAMPTZ DEFAULT NOW()
```

**Indeksy:**
```sql
idx_file_imports_created_at   ON created_at DESC
idx_file_imports_status       ON status
idx_file_imports_category_id  ON category_id
idx_file_imports_user_email   ON user_email
```

**Szacowana liczba wierszy:** 100-1000 import√≥w

---

## üîí Row Level Security (RLS)

**Status:** ‚úÖ W≈ÇƒÖczone na wszystkich tabelach

### Polityki RLS (Obecne - Prototyp):

```sql
-- categories
CREATE POLICY "categories read" ON categories FOR SELECT USING (true);
CREATE POLICY "categories write" ON categories FOR ALL USING (true) WITH CHECK (true);

-- codes
CREATE POLICY "codes read" ON codes FOR SELECT USING (true);
CREATE POLICY "codes write" ON codes FOR ALL USING (true) WITH CHECK (true);

-- codes_categories
CREATE POLICY "codes_categories read" ON codes_categories FOR SELECT USING (true);
CREATE POLICY "codes_categories write" ON codes_categories FOR ALL USING (true) WITH CHECK (true);

-- answers
CREATE POLICY "answers UPDATE (anon ok)" ON answers FOR UPDATE USING (true) WITH CHECK (true);

-- answer_codes
CREATE POLICY "answer_codes read" ON answer_codes FOR SELECT USING (true);
CREATE POLICY "answer_codes write" ON answer_codes FOR INSERT WITH CHECK (true);
```

**‚ö†Ô∏è UWAGA:** Obecne polityki sƒÖ otwarte dla prototypu. **Przed production nale≈ºy je dostosowaƒá** do faktycznej logiki autoryzacji (auth.uid(), role-based access, etc.).

---

## üîß Funkcje i Triggery w Bazie

### 1. **`assign_whitelisted_code()`** - Auto-przypisywanie Whitelistowanych Kod√≥w

**Opis:** Automatycznie przypisuje kod do nowej odpowiedzi, je≈õli tekst zawiera whitelistowany kod.

**Trigger:**
```sql
CREATE TRIGGER trg_assign_whitelisted_code
BEFORE INSERT ON answers
FOR EACH ROW EXECUTE FUNCTION assign_whitelisted_code();
```

**Logika:**
- Je≈õli `answer_text` zawiera whitelistowany kod (`is_whitelisted = true`)
- Ustaw `selected_code = <kod>`
- Ustaw `quick_status = 'Confirmed'`
- Ustaw `general_status = 'whitelist'`
- Ustaw `coding_date = NOW()`

---

### 2. **`get_high_confidence_suggestions()`** - Pobranie Sugestii AI o Wysokiej Pewno≈õci

**Parametry:**
- `p_category_id` (BIGINT, default: NULL) - Filtruj po kategorii
- `p_min_confidence` (REAL, default: 0.85) - Minimalna pewno≈õƒá (0.0-1.0)
- `p_limit` (INT, default: 100) - Limit wynik√≥w

**Zwraca:**
```sql
answer_id       BIGINT
answer_text     TEXT
suggested_code  TEXT
confidence      REAL
reasoning       TEXT
model           TEXT
```

**U≈ºycie:**
```sql
SELECT * FROM get_high_confidence_suggestions(1, 0.90, 50);
```

---

### 3. **`get_ai_suggestion_accuracy()`** - Dok≈Çadno≈õƒá Sugestii AI

**Parametry:**
- `p_category_id` (BIGINT, default: NULL)
- `p_days` (INT, default: 30)

**Zwraca:**
```sql
total_suggestions    BIGINT
correct_suggestions  BIGINT
accuracy_rate        REAL
avg_confidence       REAL
```

---

### 4. **`get_top_ai_suggested_codes()`** - Top Sugerowane Kody

**Parametry:**
- `p_category_id` (BIGINT, default: NULL)
- `p_limit` (INT, default: 20)

**Zwraca:**
```sql
code_name         TEXT
suggestion_count  BIGINT
avg_confidence    REAL
min_confidence    REAL
max_confidence    REAL
```

---

### 5. **`get_import_stats()`** - Statystyki Import√≥w

**Parametry:**
- `days` (INTEGER, default: 7)

**Zwraca:**
```sql
total_imports          BIGINT
successful_imports     BIGINT
failed_imports         BIGINT
total_rows_imported    BIGINT
avg_processing_time_ms NUMERIC
```

---

### 6. **`get_recent_imports()`** - Ostatnie Importy

**Parametry:**
- `limit_count` (INTEGER, default: 20)

**Zwraca:**
```sql
id                  UUID
file_name           TEXT
category_name       TEXT
rows_imported       INTEGER
rows_skipped        INTEGER
user_email          TEXT
status              TEXT
error_message       TEXT
file_size_kb        NUMERIC
processing_time_ms  INTEGER
created_at          TIMESTAMPTZ
```

---

## üìà Szacunkowa Liczba U≈ºytkownik√≥w

**Status:** Aplikacja jest **prototypem/MVP** przygotowanym do **Enterprise SaaS**.

### Obecne Wykorzystanie:
- **U≈ºytkownicy:** 1-5 (team TGM Research)
- **≈örodowisko:** Development/Staging
- **Dane testowe:** ~1,000-10,000 wierszy odpowiedzi

### Potencjalna Skala (Po Uruchomieniu Production):
- **U≈ºytkownicy:** 10-100+ (B2B SaaS, zespo≈Çy badawcze)
- **Dane:** 100,000+ odpowiedzi na klienta
- **Concurrent users:** 5-50

### Wymagania Przed Production:
1. ‚úÖ Upgrade Supabase z Free tier ‚Üí Pro/Team (migracja w toku)
2. ‚ö†Ô∏è Implementacja faktycznej autentykacji (Supabase Auth + RLS policies)
3. ‚ö†Ô∏è Zaostrzenie polityk RLS (user_id-based access)
4. ‚úÖ Rate limiting (ju≈º zaimplementowane)
5. ‚úÖ Security hardening (input validation, XSS protection - done)
6. ‚ö†Ô∏è Monitoring i logging (Sentry - czƒô≈õciowo wdro≈ºone)

---

## üì¶ Pe≈Çny Schemat Bazy - Export do Migracji

### Kolejno≈õƒá Uruchamiania Migracji SQL:

```bash
# 1. Podstawowe tabele
docs/sql/2025-categories-ui.sql          # Tabela categories
docs/sql/2025-codes-and-relations.sql    # Tabele codes + codes_categories + triggery
docs/sql/2025-answers-codes.sql          # Tabela answer_codes (relacja N:M)

# 2. Rozszerzenia tabeli answers
docs/sql/2025-answers-dashboard.sql      # Dodatkowe kolumny do tabeli answers

# 3. AI Features
docs/sql/2025-10-07-add-ai-suggestions.sql  # Kolumna ai_suggestions (JSONB) + funkcje

# 4. Import History
docs/sql/2025-file-imports-history.sql   # Tabela file_imports

# 5. Opcjonalne Optymalizacje (je≈õli potrzebne)
docs/sql/2025-apply-optimizations.sql    # Indeksy i optymalizacje wydajno≈õci
docs/sql/2025-full-text-search.sql       # Full-text search (je≈õli potrzebne)
```

---

## üîÑ Kroki Migracji Supabase (Free ‚Üí Paid)

### 1. **Przygotowanie**
```bash
# Backup danych (wykonaj w Supabase SQL Editor)
SELECT * FROM answers INTO answers_backup_20251013;
SELECT * FROM categories INTO categories_backup_20251013;
SELECT * FROM codes INTO codes_backup_20251013;
SELECT * FROM codes_categories INTO codes_categories_backup_20251013;
```

### 2. **Export Danych**
- Supabase Dashboard ‚Üí Table Editor ‚Üí Export as CSV (dla ka≈ºdej tabeli)
- LUB u≈ºyj: `pg_dump` (je≈õli masz bezpo≈õredni dostƒôp do PostgreSQL)

### 3. **Nowy Projekt (Paid Tier)**
1. Utw√≥rz nowy projekt Supabase (Pro/Team tier)
2. Zapisz nowe credentials:
   - `VITE_SUPABASE_URL`
   - `VITE_SUPABASE_ANON_KEY`

### 4. **Uruchom Migracje SQL**
1. Otw√≥rz **SQL Editor** w nowym projekcie
2. Wykonaj pliki SQL w podanej kolejno≈õci (sekcja wy≈ºej)
3. Sprawd≈∫, ≈ºe wszystkie tabele i funkcje zosta≈Çy utworzone:
   ```sql
   SELECT table_name FROM information_schema.tables
   WHERE table_schema = 'public';
   ```

### 5. **Import Danych**
- Supabase Dashboard ‚Üí Table Editor ‚Üí Import CSV
- LUB u≈ºyj: `psql` + `COPY` command

### 6. **Aktualizuj `.env`**
```env
VITE_SUPABASE_URL=https://new-project.supabase.co
VITE_SUPABASE_ANON_KEY=new_anon_key_here
```

### 7. **Testowanie**
```bash
# Uruchom aplikacjƒô lokalnie
npm run dev

# Sprawd≈∫ po≈ÇƒÖczenie z nowƒÖ bazƒÖ
# Przetestuj:
# - Dodawanie kategorii
# - Dodawanie kod√≥w
# - Import pliku CSV
# - Sugestie AI
# - Filtrowanie
```

### 8. **Deployment**
```bash
# Zaktualizuj env vars w production (Vercel/Netlify)
# Redeploy aplikacji
npm run build
vercel --prod  # lub netlify deploy --prod
```

---

## üìû Kontakt i Wsparcie

**Email:** support@tgmresearch.com
**GitHub:** https://github.com/your-org/coding-ui
**Dokumentacja:** `/Users/greglas/coding-ui/docs/`

---

## ‚úÖ Podsumowanie dla Migracji

### Co Robi Aplikacja?
‚úÖ **Enterprise SaaS do kategoryzacji danych badawczych z AI (GPT-4)**

### Czy Ma W≈ÇasnƒÖ Bazƒô w Supabase?
‚úÖ **TAK** - PostgreSQL + Realtime w Supabase

### G≈Ç√≥wne Tabele:
1. ‚úÖ **`answers`** - Odpowiedzi z bada≈Ñ (10k+ wierszy)
2. ‚úÖ **`categories`** - Kategorie kodowania (10-50)
3. ‚úÖ **`codes`** - Kody kategoryzacji (50-500)
4. ‚úÖ **`codes_categories`** - Relacja N:M (100-1000)
5. ‚úÖ **`answer_codes`** - Relacja N:M (10k+)
6. ‚úÖ **`file_imports`** - Historia import√≥w (100-1000)

### Liczba U≈ºytkownik√≥w:
‚úÖ **Obecne:** 1-5 (development)
‚úÖ **Docelowe:** 10-100+ (B2B SaaS production)

---

**Gotowe do migracji! üöÄ**

Je≈õli masz pytania, sprawd≈∫ dokumentacjƒô w `/docs/` lub kontaktuj siƒô z zespo≈Çem.


